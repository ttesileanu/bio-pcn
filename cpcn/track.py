"""Define a class to track model tensors."""


import torch

from types import SimpleNamespace
from typing import Union, Iterable, Callable


def _dispatch_values(
    reporter: Callable,
    name: str,
    field: Union[str, dict],
    idx: int,
    value: Union[None, int, float, Iterable, torch.Tensor] = None,
    **kwargs,
):
    """Pass values to a reporter, handling lists or tensors, as well as dicts for
    multi-parameter reports.
    """
    if not isinstance(field, str):
        if value is not None:
            raise ValueError("Tracker: value used with multi-parameter report")

        for crt_key, crt_value in field.items():
            reporter(name, crt_key, idx, crt_value, **kwargs)
        return

    if not torch.is_tensor(value):
        if isinstance(value, int):
            value = torch.LongTensor([value])
        elif hasattr(value, "__iter__"):
            for i, sub_value in enumerate(value):
                reporter(name, f"{field}:{i}", idx, sub_value, **kwargs)
            return
        else:
            value = torch.FloatTensor([value])
    else:
        value = value.detach().cpu().clone()

    reporter(name, field, idx, value, **kwargs)


class _Reporter:
    """Helper for Tracker, used to report new values."""

    def __init__(self, tracker: "Tracker"):
        """Construct the reporter.
        
        :param tracker: associated tracker object
        """
        self._tracker = tracker
        self._last_idx = {}

    def __getattr__(self, name: str):
        if self._tracker.finalized:
            raise ValueError("Tracker: attempt to report after finalize")

        # make a history field, if it does not exist
        if not hasattr(self._tracker.history, name):
            setattr(self._tracker.history, name, {})
            self._last_idx[name] = None
        reporter = self._report
        return lambda *args, name=name, reporter=reporter, **kwargs: _dispatch_values(
            reporter, name, *args, **kwargs
        )

    def _report(
        self,
        name: str,
        field: Union[str, dict],
        idx: int,
        value: Union[None, int, float, Iterable, torch.Tensor] = None,
        meld: bool = False,
        overwrite: bool = False,
    ):
        if not meld:
            value.unsqueeze_(0)

        index_name = self._tracker.index_name
        target = getattr(self._tracker.history, name)
        for key in [index_name, field]:
            if key not in target:
                target[key] = []

        idxs = target[index_name]

        # try to make sure we don't have mismatched entries
        assert len(target[field]) == len(idxs) or len(target[field]) == len(idxs) - 1

        last_idx = self._last_idx[name]
        if last_idx is None or last_idx != idx:
            # simply add new entry
            idxs.append(torch.LongTensor(len(value) * [idx]))
            target[field].append(value)
        else:
            # no need to add another entry in index array...
            # ...but did we already have an entry in this field?
            if len(target[field]) < len(idxs):
                # make sure the length of this value entry matches previous ones for the
                # same index
                if len(value) != len(idxs[-1]):
                    raise ValueError("Tracker: mismatched batch size for meld == True")
                # no; add the entry
                target[field].append(value)
            else:
                if overwrite:
                    target[field][-1] = value
                else:
                    if len(value) > 1:
                        raise ValueError(
                            "Tracker: repeated entry not allowed when meld == True"
                        )

                    # yes: keep track of all the entries, to average over them later
                    if torch.is_tensor(target[field][-1]):
                        target[field][-1] = [target[field][-1]]
                    target[field][-1].append(value)

        self._last_idx[name] = idx


class Tracker:
    """Tracker for tensor and list-of-tensor values.
    
    Call as
        tracker.report.test("field", idx, value)
    to add an entry in the `"field"` field of the `test` dictionary in the `history`.
    This adds the `value` to the `"field"`, and the given `idx` to the `"idx"` field
    inside `tracker.history.test`.

    If `value` is a `Tensor`, it is added as-is. If it is an iterable other than
    `Tensor`, it is considered "layered" variable. An entry is recorded for each of its
    elements, with field name generated by adding `":{layer}"` to `"field"`. Note that
    therefore there is a big difference in behavior between reporting the 2d tensor
        torch.FloatTensor([[1.0, 2.0, 3.0]])
    and reporting the list of tensors
        [torch.FloatTensor([1.0]), torch.FloatTensor([2.0]), torch.FloatTensor([3.0])] .

    If several reports are made for the same variable at the same index, they are
    combined by averaging in the `finalize` stage. Thus in general each index will
    appear once.

    Multiple values can be recorded at once by using a `dict` for the first argument:
        tracker.report.test({"foo": 2, "bar": 3}, idx=1)

    There is a way to submit several entries for the same index, which can be useful if
    we wish to, e.g., store a batch of results. This can be achieved by using the `meld`
    argument to `report`:
        tracker.report.test("field", idx, value, meld=True)
    If `value` is a tensor, a new entry is generated for each row in `value`. If it is a
    different iterable, then the same is done *per layer*. This will generate as many
    entries as the length of the tensors. The constraint here is that, if we store more
    than one field per namespace, all have to have the same batch size. Repeated entries
    for the same index are not allowed when `meld == True`.
    """

    def __init__(self, index_name: str = "idx"):
        """Construct tracker.
        
        :param index_name: name of the index field
        """
        self.index_name = index_name
        self.history = SimpleNamespace()
        self.finalized = False
        self.report = _Reporter(self)

    def finalize(self):
        """Finalize recording, coalesce history into coherent tensors."""
        for field in self.history.__dict__:
            target = getattr(self.history, field)

            for key in target:
                # go through, find and process repeated entries
                if key != self.index_name:
                    for i, value in enumerate(target[key]):
                        if not torch.is_tensor(value):
                            sum = 0
                            for x in value:
                                sum = sum + x
                            target[key][i] = sum / len(value)

                # coalesce
                target[key] = torch.cat(target[key])

        self.finalized = True

    def set_index_name(self, index_name: str):
        """Set the name used as index."""
        self.index_name = index_name

    def __repr__(self) -> str:
        s = f"Tracker(index_name={self.index_name}, finalized={self.finalized}, "
        hist = "history=namespace("
        for i, name in enumerate(self.history.__dict__):
            if i > 0:
                hist += ", "
            sub_s = f"{name}={{" + ", ".join(
                f'"{_}"' for _ in getattr(self.history, name).keys()
            )
            hist += sub_s + "}"
        hist += ")"
        s += hist + ")"

        return s
